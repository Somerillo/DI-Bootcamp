{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Exercise 1 : Defining the Problem and Data Collection for Loan Default Prediction\n",
    "\n",
    "## Problem Statement\n",
    "The goal of this project is to develop a predictive model that can identify the likelihood of a loan applicant defaulting on their loan. By accurately predicting loan defaults, financial institutions can minimize risks, optimize lending strategies, and improve overall profitability. The model will leverage historical data to predict whether an applicant is likely to default, enabling proactive decision-making.\n",
    "\n",
    "## Types of Data Required\n",
    "To build an effective loan default prediction model, the following types of data are required:\n",
    "\n",
    "1. **Applicant Personal Details**:\n",
    "   - Age\n",
    "   - Gender\n",
    "   - Marital status\n",
    "   - Employment status\n",
    "   - Education level\n",
    "\n",
    "2. **Financial Information**:\n",
    "   - Annual income\n",
    "   - Debt-to-income ratio\n",
    "   - Savings and checking account balances\n",
    "\n",
    "3. **Credit History**:\n",
    "   - Credit score\n",
    "   - Number of open credit lines\n",
    "   - Length of credit history\n",
    "   - Past delinquencies (if any)\n",
    "\n",
    "4. **Loan Details**:\n",
    "   - Loan amount requested\n",
    "   - Loan term (e.g., 12 months, 36 months)\n",
    "   - Loan purpose (e.g., home improvement, education)\n",
    "   - Interest rate\n",
    "\n",
    "5. **Repayment History**:\n",
    "   - Payment history for previous loans (on-time payments, late payments)\n",
    "   - Default history (if any)\n",
    "\n",
    "6. **Other Relevant Features**:\n",
    "   - Co-applicant details (if applicable)\n",
    "   - Collateral value (if secured loan)\n",
    "\n",
    "## Data Sources\n",
    "The data required for this project can be collected from the following sources:\n",
    "\n",
    "1. **Financial Institutionâ€™s Internal Records**:\n",
    "   - Historical loan application and repayment data.\n",
    "   - Customer profiles and transaction histories.\n",
    "\n",
    "2. **Credit Bureaus**:\n",
    "   - Credit scores and detailed credit reports.\n",
    "   - Information on delinquencies and credit utilization.\n",
    "\n",
    "3. **Publicly Available Datasets**:\n",
    "   - Open datasets related to financial lending and defaults (e.g., Kaggle, UCI Machine Learning Repository).\n",
    "\n",
    "4. **Third-Party Data Providers**:\n",
    "   - Companies specializing in financial data aggregation.\n",
    "\n",
    "5. **Government Agencies**:\n",
    "   - Public records on economic indicators or demographic data that may influence loan defaults.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Exercise 2 : Feature Selection and Model Choice for Loan Default Prediction\n",
    "\n",
    "## About Dataset\n",
    "\n",
    "Among all industries, insurance domain has the largest use of analytics & data science methods. This data set would provide you enough taste of working on data sets from insurance companies, what challenges are faced, what strategies are used, which variables influence the outcome etc. This is a classification problem. The data has 615 rows and 13 columns.\n",
    "\n",
    "\n",
    "Problem-----\n",
    "\n",
    "\n",
    "Company wants to automate the loan eligibility process (real time) based on customer detail provided while filling online application form. These details are Gender, Marital Status, Education, Number of Dependents, Income, Loan Amount, Credit History and others. To automate this process, they have given a problem to identify the customers segments, those are eligible for loan amount so that they can specifically target these customers. Here they have provided a partial data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'train_u6lujuX_CVtuZ9i (1).csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Features for Predicting Loan Defaults\n",
    "\n",
    "1. **Credit_History**\n",
    "   - **Why Relevant**: This is one of the most critical predictors of loan defaults. Applicants with a history of timely repayments are less likely to default.\n",
    "   - **Type**: Numerical (binary: 1.0 = good credit history, 0.0 = bad credit history).\n",
    "\n",
    "2. **ApplicantIncome**\n",
    "   - **Why Relevant**: Higher income generally indicates a greater ability to repay loans. However, it should be analyzed in conjunction with other factors like loan amount and debt-to-income ratio.\n",
    "   - **Type**: Numerical.\n",
    "\n",
    "3. **CoapplicantIncome**\n",
    "   - **Why Relevant**: If there is a co-applicant contributing income, it can improve the applicant's ability to repay the loan.\n",
    "   - **Type**: Numerical.\n",
    "\n",
    "4. **LoanAmount**\n",
    "   - **Why Relevant**: The size of the loan relative to the applicant's income can indicate whether the loan is affordable for the applicant.\n",
    "   - **Type**: Numerical.\n",
    "\n",
    "5. **Loan_Amount_Term**\n",
    "   - **Why Relevant**: Longer loan terms may reduce monthly payments but increase overall interest, which can impact repayment ability.\n",
    "   - **Type**: Numerical.\n",
    "\n",
    "6. **Married**\n",
    "   - **Why Relevant**: Being married might indicate shared financial responsibilities or additional sources of income, potentially affecting repayment ability.\n",
    "   - **Type**: Categorical.\n",
    "\n",
    "7. **Dependents**\n",
    "   - **Why Relevant**: Having dependents increases financial obligations, which could impact an applicant's ability to repay loans.\n",
    "   - **Type**: Categorical.\n",
    "\n",
    "8. **Education**\n",
    "   - **Why Relevant**: Education level may correlate with job stability and income potential, influencing repayment behavior.\n",
    "   - **Type**: Categorical.\n",
    "\n",
    "9. **Self_Employed**\n",
    "   - **Why Relevant**: Self-employed individuals might have variable income streams, which could affect their ability to make consistent repayments.\n",
    "   - **Type**: Categorical.\n",
    "\n",
    "10. **Property_Area**\n",
    "   - **Why Relevant**: The location of the property (Urban, Semiurban, Rural) might influence economic opportunities and repayment behavior.\n",
    "   - **Type**: Categorical.\n",
    "\n",
    "11. **Loan_Status (Target Variable)**\n",
    "   - This is the target variable for prediction:\n",
    "     - `Y`: Loan approved (no default).\n",
    "     - `N`: Loan rejected or defaulted.\n",
    "\n",
    "### Less Relevant Features\n",
    "- **Loan_ID**:\n",
    "  - This is just an identifier and does not contribute to predicting loan defaults.\n",
    "\n",
    "### Feature Engineering Suggestions\n",
    "1. Calculate a derived feature like the debt-to-income ratio:\n",
    "   $$\n",
    "   \\text{Debt-to-Income Ratio} = \\frac{\\text{LoanAmount}}{\\text{ApplicantIncome} + \\text{CoapplicantIncome}}\n",
    "   $$\n",
    "2. Handle missing values in critical features like `LoanAmount` and `Credit_History`.\n",
    "3. Encode categorical variables like `Gender`, `Married`, `Education`, etc., for machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Exercise 3 : Training, Evaluating, and Optimizing the Model\n",
    "\n",
    "## Model Selection\n",
    "For predicting loan defaults, the following machine learning models are recommended based on their performance in similar tasks:\n",
    "\n",
    "1. **Logistic Regression**:\n",
    "   - Simple and interpretable model ideal for binary classification problems.\n",
    "   - Performs well with smaller datasets and fewer features.\n",
    "\n",
    "2. **Decision Tree**:\n",
    "   - Non-linear model that captures complex relationships in data.\n",
    "   - Easy to interpret but prone to overfitting.\n",
    "\n",
    "3. **Random Forest**:\n",
    "   - Ensemble method that reduces overfitting by averaging multiple decision trees.\n",
    "   - Consistently shows high accuracy and robustness in loan prediction tasks.\n",
    "\n",
    "4. **Gradient Boosting Models (e.g., XGBoost, LightGBM)**:\n",
    "   - Powerful models that handle imbalanced datasets well.\n",
    "   - Effective for improving prediction accuracy through boosting techniques.\n",
    "\n",
    "5. **AdaBoost**:\n",
    "   - Another ensemble method that combines weak learners to create a strong classifier.\n",
    "   - Known for achieving high accuracy in loan default predictions.\n",
    "\n",
    "6. **Neural Networks**:\n",
    "   - Suitable for large datasets with complex feature interactions.\n",
    "   - Requires significant computational resources and careful tuning.\n",
    "\n",
    "## Steps to Evaluate the Modelâ€™s Performance\n",
    "\n",
    "### 1. **Split the Dataset**\n",
    "   - Divide the dataset into training (70-80%) and testing (20-30%) sets to evaluate generalization performance.\n",
    "\n",
    "### 2. **Train the Model**\n",
    "   - Train the selected models on the training set using appropriate hyperparameters.\n",
    "\n",
    "### 3. **Evaluate Using Relevant Metrics**\n",
    "   The following metrics are crucial for assessing model performance in loan default prediction:\n",
    "\n",
    "   - **Accuracy**: Measures the overall correctness of predictions.\n",
    "     $$\n",
    "     \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "     $$\n",
    "\n",
    "   - **Precision**: Indicates how many predicted defaults were actual defaults (important to minimize false positives).\n",
    "     $$\n",
    "     \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "     $$\n",
    "\n",
    "   - **Recall (Sensitivity)**: Reflects how many actual defaults were correctly identified (important to minimize false negatives).\n",
    "     $$\n",
    "     \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "     $$\n",
    "\n",
    "   - **F1-Score**: Harmonic mean of precision and recall, balancing both metrics.\n",
    "     $$\n",
    "     F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "     $$\n",
    "\n",
    "   - **ROC-AUC (Receiver Operating Characteristic â€“ Area Under Curve)**:\n",
    "     - Evaluates the modelâ€™s ability to distinguish between classes across different thresholds.\n",
    "     - A higher AUC indicates better performance.\n",
    "\n",
    "### 4. **Handle Imbalanced Data**\n",
    "   - Use techniques like oversampling (SMOTE), undersampling, or class-weight adjustments if default cases are rare.\n",
    "\n",
    "### 5. **Hyperparameter Tuning**\n",
    "   - Optimize model parameters using techniques like Grid Search or Random Search to improve performance.\n",
    "\n",
    "### 6. **Cross-Validation**\n",
    "   - Perform k-fold cross-validation to ensure the model generalizes well across different subsets of data.\n",
    "\n",
    "### 7. **Compare Models**\n",
    "   - Compare all selected models based on the above metrics and choose the one with the best trade-off between precision, recall, and AUC-ROC.\n",
    "\n",
    "### 8. **Test on Holdout Set**\n",
    "   - Validate the final model on an unseen holdout test set to confirm its real-world applicability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Designing Machine Learning Solutions for Specific Problems\n",
    "\n",
    "1. **Predicting Stock Prices**\n",
    "   - **Type of Machine Learning**: **Supervised Learning (Regression)**\n",
    "   - **Explanation**:\n",
    "     - Predicting stock prices involves forecasting continuous numerical values (e.g., the price of a stock at a future time).\n",
    "     - Supervised learning is suitable because we have historical stock price data (features like previous prices, trading volume, market indicators) and corresponding target values (future prices).\n",
    "     - Regression models such as Linear Regression, LSTM (Long Short-Term Memory networks), or ARIMA (AutoRegressive Integrated Moving Average) are commonly used for time series forecasting tasks like this.\n",
    "\n",
    "\n",
    "\n",
    "2. **Organizing a Library of Books**\n",
    "   - **Type of Machine Learning**: **Unsupervised Learning (Clustering)**\n",
    "   - **Explanation**:\n",
    "     - Grouping books into genres or categories based on similarities is an unsupervised learning task because the goal is to discover inherent patterns in the data without predefined labels.\n",
    "     - Features like book descriptions, keywords, or metadata can be used to calculate similarity between books.\n",
    "     - Clustering algorithms such as K-Means, Hierarchical Clustering, or DBSCAN can group books into clusters that represent genres or categories.\n",
    "\n",
    "\n",
    "\n",
    "3. **Program a Robot to Navigate and Find the Shortest Path in a Maze**\n",
    "   - **Type of Machine Learning**: **Reinforcement Learning**\n",
    "   - **Explanation**:\n",
    "     - This problem involves teaching the robot to take actions in an environment (the maze) to maximize a reward (finding the shortest path to the goal).\n",
    "     - Reinforcement Learning (RL) is suitable because it focuses on learning optimal actions through trial and error by interacting with the environment.\n",
    "     - Algorithms like Q-Learning or Deep Q-Networks (DQN) can be used to train the robot to navigate efficiently.\n",
    "     - The robot receives feedback (positive reward for moving closer to the goal, negative reward for hitting walls), enabling it to learn an optimal strategy over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒŸ Exercise 5 : Designing an Evaluation Strategy for Different ML Models\n",
    "\n",
    "## 1. **Supervised Learning Model (e.g., Classification Model)**\n",
    "\n",
    "### Evaluation Strategy\n",
    "- **Metrics**:\n",
    "  - **Accuracy**: Measures the overall correctness of predictions.\n",
    "    $$\n",
    "    \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}}\n",
    "    $$\n",
    "  - **Precision**: Focuses on how many predicted positives are actual positives (important if false positives are costly).\n",
    "    $$\n",
    "    \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "    $$\n",
    "  - **Recall (Sensitivity)**: Measures how many actual positives were correctly identified (important if false negatives are costly).\n",
    "    $$\n",
    "    \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n",
    "    $$\n",
    "  - **F1-Score**: Harmonic mean of precision and recall, balancing both metrics.\n",
    "    $$\n",
    "    F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "    $$\n",
    "  - **ROC-AUC (Receiver Operating Characteristic â€“ Area Under Curve)**: Evaluates the model's ability to distinguish between classes across different thresholds.\n",
    "\n",
    "- **Methods**:\n",
    "  - **Train-Test Split**: Divide the dataset into training and testing sets (e.g., 80%-20% split) to evaluate generalization performance.\n",
    "  - **Cross-Validation**: Use k-fold cross-validation to ensure the model performs well across different subsets of the data.\n",
    "  - **Confusion Matrix**: Analyze TP, TN, FP, and FN to understand prediction errors.\n",
    "  - **ROC Curve**: Plot the true positive rate (TPR) vs. false positive rate (FPR) to assess classification thresholds.\n",
    "\n",
    "### Challenges and Limitations\n",
    "- Imbalanced datasets can skew metrics like accuracy; precision, recall, and F1-score are more informative in such cases.\n",
    "- Cross-validation can be computationally expensive for large datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. **Unsupervised Learning Model (e.g., Clustering Model)**\n",
    "\n",
    "### Evaluation Strategy\n",
    "- **Techniques**:\n",
    "  - **Silhouette Score**:\n",
    "    - Measures how similar an object is to its own cluster compared to other clusters.\n",
    "    - Values range from -1 (poor clustering) to +1 (good clustering).\n",
    "  - **Elbow Method**:\n",
    "    - Plots the within-cluster sum of squares (WCSS) against the number of clusters.\n",
    "    - The \"elbow point\" indicates the optimal number of clusters.\n",
    "  - **Cluster Validation Metrics**:\n",
    "    - **Davies-Bouldin Index**: Measures cluster compactness and separation. Lower values indicate better clustering.\n",
    "    - **Dunn Index**: Ratio of minimum inter-cluster distance to maximum intra-cluster distance. Higher values are better.\n",
    "\n",
    "- **Visualization**:\n",
    "  - Use dimensionality reduction techniques like PCA or t-SNE to visualize clusters in a low-dimensional space.\n",
    "\n",
    "### Challenges and Limitations\n",
    "- Unsupervised learning lacks ground truth labels, making evaluation subjective.\n",
    "- Metrics like silhouette score may not work well for non-spherical or overlapping clusters.\n",
    "- Choosing the \"right\" number of clusters is often ambiguous.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. **Reinforcement Learning Model**\n",
    "\n",
    "### Evaluation Strategy\n",
    "- **Metrics**:\n",
    "  - **Cumulative Reward**:\n",
    "    - The total reward accumulated by the agent over an episode or series of episodes.\n",
    "    - Higher cumulative rewards indicate better performance.\n",
    "  - **Convergence**:\n",
    "    - Measure how quickly the agent's policy stabilizes and stops improving significantly.\n",
    "  - **Exploration vs. Exploitation Balance**:\n",
    "    - Assess whether the agent explores sufficiently before settling into exploitation mode. This can be tracked using exploration rates (e.g., epsilon in epsilon-greedy strategies).\n",
    "\n",
    "- **Methods**:\n",
    "  - Simulate multiple episodes and track cumulative rewards over time to evaluate learning progress.\n",
    "  - Compare learned policies with baseline strategies or heuristics to assess effectiveness.\n",
    "  - Visualize state-action trajectories to ensure that the agent learns optimal paths or actions.\n",
    "\n",
    "### Challenges and Limitations\n",
    "- Reinforcement learning often requires extensive computational resources due to repeated simulations or interactions with the environment.\n",
    "- Balancing exploration and exploitation effectively is challenging and problem-specific.\n",
    "- Convergence may be slow or unstable in complex environments with high-dimensional state spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Devs_Institute",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
