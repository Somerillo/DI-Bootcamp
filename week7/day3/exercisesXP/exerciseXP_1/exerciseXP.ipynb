{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project 1: Scraping Data from a Dynamic Webpage\n",
    "- Install necessary Python libraries: selenium, beautifulsoup4 (bs4), and chromedriver-autoinstaller.\n",
    "- Choose a dynamic webpage for scraping. For this project, we will scrape dynamic product data from a demo e-commerce site, like : [inmotionhosting](https://www.inmotionhosting.com/).\n",
    "\n",
    "\n",
    "## Task\n",
    "\n",
    "- Initialize Selenium WebDriver\n",
    "- Load the Web Page\n",
    "- Identify the elements that contain hosting plan details.\n",
    "- Extract necessary data such as plan names, features, and pricing.\n",
    "- Store and Save the Data\n",
    "- Close Selenium WebDriver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup Selenium WebDriver\n",
    "# options = webdriver.ChromeOptions()\n",
    "# options.add_argument(\"--start-maximized\")\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# # InMotion Hosting page\n",
    "# url = \"https://www.inmotionhosting.com/\"\n",
    "# driver.get(url)\n",
    "\n",
    "\n",
    "# for i in range(5):  # Limit to 5 buttons\n",
    "#     try:\n",
    "#         # Wait for the container with buttons to load\n",
    "#         wait = WebDriverWait(driver, 30)\n",
    "#         container = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.imh-rostrum-container\")))\n",
    "        \n",
    "#         # Find all buttons within the container\n",
    "#         buttons = container.find_elements(By.CSS_SELECTOR, \"a.cta-link.btn-secondary-alt\")\n",
    "        \n",
    "#         # Click the button\n",
    "#         driver.execute_script(\"arguments[0].click();\", buttons[i])\n",
    "#         print(f\"\\nClicked button {i+1}\") # Visual confirmation\n",
    "        \n",
    "#         # Wait for the page to load after clicking\n",
    "#         WebDriverWait(driver, 10).until(EC.staleness_of(container))\n",
    "        \n",
    "#         # Process nested content\n",
    "#         nested_soups = process_nested_content(driver)\n",
    "#         print(f\"Captured {len(nested_soups)} term soups for main button {i+1}\")\n",
    "        \n",
    "#         # Get the page source and create a BeautifulSoup object\n",
    "#         soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#         soups.append(soup)\n",
    "        \n",
    "#         print(f\"Captured soup for button {i+1}\") # Visual confirmation\n",
    "#         print('=' * 50)\n",
    "        \n",
    "#         # Navigate back to the initial page\n",
    "#         driver.back()\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred while processing button {i+1}: {str(e)}\")\n",
    "\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It clicks on the first button twice, then jumps to the third where all the structure is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected unique links:\n",
      "https://www.inmotionhosting.com/shared-hosting\n",
      "https://www.inmotionhosting.com/vps-hosting\n",
      "https://www.inmotionhosting.com/dedicated-servers\n",
      "https://www.inmotionhosting.com/wordpress-hosting\n",
      "https://www.inmotionhosting.com/wordpress-hosting/managed-wordpress\n"
     ]
    }
   ],
   "source": [
    "# setup selenium webdriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# inmotion hosting page\n",
    "url = \"https://www.inmotionhosting.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "links = []  # list to store unique links\n",
    "seen_links = set()  # set to track seen links for uniqueness\n",
    "\n",
    "try:\n",
    "    # wait for the container with buttons to load\n",
    "    wait = WebDriverWait(driver, 30)\n",
    "    container = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.imh-rostrum-container\")))\n",
    "    \n",
    "    # find all buttons within the container\n",
    "    buttons = container.find_elements(By.CSS_SELECTOR, \"a.cta-link.btn-secondary-alt\")\n",
    "    \n",
    "    # extract links from all buttons while maintaining order\n",
    "    for button in buttons:\n",
    "        link = button.get_attribute(\"href\")  # get the href attribute of the button\n",
    "        if link and link not in seen_links:  # check if link is not None or empty and not already seen\n",
    "            links.append(link)  # add link to the list to maintain order\n",
    "            seen_links.add(link)  # add link to the set for uniqueness\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"an error occurred: {str(e)}\")\n",
    "\n",
    "# print all collected unique links in order of appearance\n",
    "print(\"collected unique links:\")\n",
    "for link in links:\n",
    "    print(link)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we browse to each of the adresses retrieved by clicking the plan buttons.\n",
    "\n",
    "Some of the nested pages require to accept the cookies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_cookies(driver):\n",
    "    \"\"\"\n",
    "    click and accept all cookies on the page if the button is present.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # wait for the cookie consent button to be present\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        cookie_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button.cookie-accept-button\")))  # Update the selector as needed\n",
    "        \n",
    "        # click the button to accept cookies\n",
    "        cookie_button.click()\n",
    "        print(\"accepted cookies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"error accepting cookies: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrap the first link: open the link and click all found buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Year\n",
      "1 Year\n",
      "1 Month\n"
     ]
    }
   ],
   "source": [
    "# setup selenium webdriver for the first url\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# get the first url from the links list\n",
    "url = links[0]\n",
    "\n",
    "driver.get(url)  # navigate to the current url\n",
    "\n",
    "# wait for the specific section to be present\n",
    "wait = WebDriverWait(driver, 10)\n",
    "section = wait.until(EC.presence_of_element_located((By.ID, \"shared-hosting-rostrum\")))\n",
    "\n",
    "# define the title variable by finding the h2 element\n",
    "container = section.find_element(By.CSS_SELECTOR, \"div.container\")\n",
    "plan_title = container.find_element(By.TAG_NAME, \"h2\").text  # get the text of the h2 element\n",
    "\n",
    "# find all term selector buttons within this specific section\n",
    "term_buttons = section.find_elements(By.CSS_SELECTOR, \"button.imh-term-selector\")\n",
    "\n",
    "# list to store dictionaries for each button clicked\n",
    "soups = []\n",
    "\n",
    "# click each button, print its name, and create a soup\n",
    "for button in term_buttons:\n",
    "    try:\n",
    "        # scroll the button into view\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", button)\n",
    "        \n",
    "        # wait until the button is clickable\n",
    "        wait.until(EC.element_to_be_clickable(button))\n",
    "\n",
    "        # click the button using JavaScript as a fallback\n",
    "        driver.execute_script(\"arguments[0].click();\", button)\n",
    "        \n",
    "        print(button.text)  # print the name of the button\n",
    "        \n",
    "        # wait for the content to load after clicking\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.imh-rostrum-container\")))\n",
    "        \n",
    "        # create a soup from the specified division after clicking\n",
    "        container_html = driver.find_element(By.CSS_SELECTOR, \"div.imh-rostrum-container\").get_attribute('outerHTML')\n",
    "        soup = BeautifulSoup(container_html, 'html.parser')\n",
    "        \n",
    "        # append a dictionary with button text and soup to the list\n",
    "        soups.append({'button': button.text, 'soup': soup})  # store as a dictionary\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error clicking button {button.text}: {str(e)}\")\n",
    "\n",
    "driver.quit()  # close the driver after processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extracted all the soups in a list, they are retrieved into a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Plan                                          Sub-Title  \\\n",
      "0      3 Year Core  Suitable for simple sites, with everything you...   \n",
      "1    3 Year Launch  Designed for seamless multi-site management & ...   \n",
      "2     3 Year Power  Powerful resources perfect for larger sites & ...   \n",
      "3       3 Year Pro  Ideal for high-traffic or eCommerce sites with...   \n",
      "4      1 Year Core  Suitable for simple sites, with everything you...   \n",
      "5    1 Year Launch  Designed for seamless multi-site management & ...   \n",
      "6     1 Year Power  Powerful resources perfect for larger sites & ...   \n",
      "7       1 Year Pro  Ideal for high-traffic or eCommerce sites with...   \n",
      "8     1 Month Core  Suitable for simple sites, with everything you...   \n",
      "9   1 Month Launch  Designed for seamless multi-site management & ...   \n",
      "10   1 Month Power  Powerful resources perfect for larger sites & ...   \n",
      "11     1 Month Pro  Ideal for high-traffic or eCommerce sites with...   \n",
      "\n",
      "                                              Pricing  \\\n",
      "0   You Save 68%Starting at$3.19/moRenews at $9.99...   \n",
      "1   You Save 62%Starting at$4.99/moRenews at $12.9...   \n",
      "2   You Save 71%Starting at$4.99/moRenews at $16.9...   \n",
      "3   You Save 54%Starting at$10.99/moRenews at $23....   \n",
      "4   You Save 68%Starting at$3.19/moRenews at $9.99...   \n",
      "5   You Save 62%Starting at$4.99/moRenews at $12.9...   \n",
      "6   You Save 71%Starting at$4.99/moRenews at $16.9...   \n",
      "7   You Save 54%Starting at$10.99/moRenews at $23....   \n",
      "8   You Save 68%Starting at$3.19/moRenews at $9.99...   \n",
      "9   You Save 62%Starting at$4.99/moRenews at $12.9...   \n",
      "10  You Save 71%Starting at$4.99/moRenews at $16.9...   \n",
      "11  You Save 54%Starting at$10.99/moRenews at $23....   \n",
      "\n",
      "                                              Details  \n",
      "0   [Free domain & SSLFree domain & SSLFree domain...  \n",
      "1   [Free domain & SSLFree domain & SSLFree domain...  \n",
      "2   [Free domain & SSLFree domain & SSLFree domain...  \n",
      "3   [Free domain & SSLFree domain & SSLFree domain...  \n",
      "4   [Free domain & SSLFree domain & SSLFree domain...  \n",
      "5   [Free domain & SSLFree domain & SSLFree domain...  \n",
      "6   [Free domain & SSLFree domain & SSLFree domain...  \n",
      "7   [Free domain & SSLFree domain & SSLFree domain...  \n",
      "8   [Free domain & SSLFree domain & SSLFree domain...  \n",
      "9   [Free domain & SSLFree domain & SSLFree domain...  \n",
      "10  [Free domain & SSLFree domain & SSLFree domain...  \n",
      "11  [Free domain & SSLFree domain & SSLFree domain...  \n"
     ]
    }
   ],
   "source": [
    "# initialize lists to store data for all soups\n",
    "all_titles = []\n",
    "all_sub_titles = []\n",
    "all_pricing = []\n",
    "all_details = []\n",
    "\n",
    "# iterate through each soup in the soups list\n",
    "for soup_data in soups:\n",
    "    first_soup = soup_data['soup']  # get the current soup\n",
    "    button_text = soup_data['button']  # get the button text for this soup\n",
    "\n",
    "    # find all imh-rostrum-card elements\n",
    "    cards = first_soup.find_all(class_='imh-rostrum-card')\n",
    "\n",
    "    # extract content from each card\n",
    "    for card in cards:\n",
    "        # extract title (h3)\n",
    "        title = card.find('h3').text.strip() if card.find('h3') else 'No Title'\n",
    "        all_titles.append(f'{button_text} {title}')  # prepend button text to title\n",
    "\n",
    "        # extract sub-title\n",
    "        sub_title = card.find(class_='imh-rostrum-sub-title').text.strip() if card.find(class_='imh-rostrum-sub-title') else ''\n",
    "        all_sub_titles.append(sub_title)\n",
    "\n",
    "        # extract pricing\n",
    "        pricing_container = card.find(class_='imh-pricing-container')\n",
    "        price = pricing_container.text.strip() if pricing_container else ''\n",
    "        all_pricing.append(price)\n",
    "\n",
    "        # extract details list\n",
    "        details_list = card.find(class_='imh-rostrum-details-list')\n",
    "        if details_list:\n",
    "            details_items = [li.text.strip() for li in details_list.find_all('li')]\n",
    "            all_details.append(details_items)\n",
    "        else:\n",
    "            all_details.append([])\n",
    "\n",
    "# create dtaframe from the collected data\n",
    "df = pd.DataFrame({\n",
    "    'Plan': all_titles,\n",
    "    'Sub-Title': all_sub_titles,\n",
    "    'Pricing': all_pricing,\n",
    "    'Details': all_details\n",
    "})\n",
    "\n",
    "# kraken\n",
    "print(df)\n",
    "\n",
    "# save it into a csv\n",
    "df.to_csv(f'{plan_title}.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then rinse and repeat, each nested page from the buttons has a different structure. So we need to redo a new code for each link extracted in the list `links`\n",
    "\n",
    "Also its 3:00 AM, a new personal record!!!! i go to sleep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Devs_Institute",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
